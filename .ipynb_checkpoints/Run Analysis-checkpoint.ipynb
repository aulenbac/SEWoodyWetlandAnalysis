{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import gapproduction as gp\n",
    "import pickle\n",
    "import gappanalysis as ga\n",
    "import arcpy\n",
    "pd.set_option('display.width', 1000)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important variables\n",
    "Name of the project directories where input data and results belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workDir = \"T:/Floodplain_Forests_2016/\"\n",
    "dataDir = workDir + \"Data/\"\n",
    "tempDir = workDir + \"Temp/\"\n",
    "intermDir = workDir + \"Intermediate/\"\n",
    "resultDir = workDir + \"Results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations of input data layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "habMapDir = \"P:/Proj3/USGap/Vert/Model/Output/CONUS/Null123/\"\n",
    "seasonalhabMapDir = \"P:/Proj3/USGap/Vert/Model/Output/CONUS/01/\"\n",
    "lcMapDir = \"P:/Proj3/USGap/Vert/Model/data/LandCover\"\n",
    "lcMap = \"P:/Proj3/USGap/Analysis/Data/lcv1vertmosai\"\n",
    "conus_extent = \"P:/Proj3/USGap/Vert/Model/data/conus_ext_cnt\"\n",
    "snap_raster = \"P:/Proj3/USGap/Vert/Model/data/snapgrid\"\n",
    "PADUS_Man = \"P:/Proj3/USGap/Analysis/Data/PAD14s2001.tif\"\n",
    "AOI = dataDir + \"StudyRegion.shp\"\n",
    "habmapSuffix = \"_CONUS_HabMap_2001v1.tif\"\n",
    "hucs = 'P:/Proj3/USGAP/Vert/Model/data/HucRng/Hucs.shp'\n",
    "overlayTable = resultDir + \"Percent_FloodplainForest/Percent_in_Floodplain_Master.csv\"\n",
    "summerRichness = resultDir + \"Top_Summer/Top_Summer_Richness.tif\"\n",
    "winterRichness = resultDir + \"Top_Winter/Top_Winter_Richness.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables related to land cover processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of floodplain forest map units.\n",
    "floodplainSystemCSV = dataDir + \"/Ecological systems of interest.csv\"\n",
    "\n",
    "# Placeholder code to use for nulls in floodplain binary map.\n",
    "placeholder_code = 99\n",
    "\n",
    "# Name of binary floodplain layer (without NoDatas)\n",
    "floodplainBinary = resultDir + \"Floodplains10&{0}.tif\".format(placeholder_code)\n",
    "\n",
    "# Name of floodplain layer (with NoDatas)\n",
    "floodplain = resultDir + \"Floodplain.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some species lists and set some names for files that will be created later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Species list derived by querying range database for native species in ecoregions\n",
    "# that could have floodplain forests. \n",
    "import pickle\n",
    "studyRegionList = pickle.load(open(resultDir + \"studyRegionList.pkl\"))\n",
    "\n",
    "# studyRegionList converted to null123 raster names.\n",
    "null123List = [i[0] + i[1:5].upper() + i[5:] + habmapSuffix for i in studyRegionList]\n",
    "\n",
    "# Location of lists of species exceeding the % habitat overlay threshold\n",
    "winterTopSpList = resultDir + \"TopWinterSpecies.csv\"\n",
    "summerTopSpList = resultDir + \"TopSummerSpecies.csv\"\n",
    "TopSpList = resultDir + \"TopSpecies.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names to use for various richness rasters that are created and used during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Paths to richness rasters\n",
    "richnessPathsCONUS = {\n",
    "\"amphibian\": dataDir + \"Amphibian_Richness.tif\",\n",
    "\"bird_summer\": dataDir + \"Bird_Summer_Richness.tif\",\n",
    "\"bird_winter\": dataDir + \"Bird_Winter_Richness.tif\",\n",
    "\"reptile\": dataDir + \"Reptile_Richness.tif\",\n",
    "\"mammal\": dataDir + \"Mammal_Richness.tif\",\n",
    "\"all_taxa\": dataDir + \"All_Richness.tif\"}\n",
    "\n",
    "richnessPathsSE = {\n",
    "\"amphibian\": resultDir + \"Amphibian_Richness_SE.tif\",\n",
    "\"bird_summer\": resultDir + \"Bird_Summer_Richness_SE.tif\",\n",
    "\"bird_winter\": resultDir + \"Bird_Winter_Richness_SE.tif\",\n",
    "\"reptile\": resultDir + \"Reptile_Richness_SE.tif\",\n",
    "\"mammal\": resultDir + \"Mammal_Richness_SE.tif\",\n",
    "\"all_taxa\": resultDir + \"All_Richness_SE.tif\"}    \n",
    "\n",
    "richnessPathsFlood = {\n",
    "\"amphibian\": resultDir + \"Amphibian_Richness_Flood.tif\",\n",
    "\"bird_summer\": resultDir + \"Bird_Summer_Richness_Flood.tif\",\n",
    "\"bird_winter\": resultDir + \"Bird_Winter_Richness_Flood.tif\",\n",
    "\"reptile\": resultDir + \"Reptile_Richness_Flood.tif\",\n",
    "\"mammal\": resultDir + \"Mammal_Richness_Flood.tif\",\n",
    "\"all_taxa\": resultDir + \"All_Richness_Flood.tif\"}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Set geoprocessing environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arcpy.ResetEnvironments()\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "arcpy.env.snapRaster=floodconfig.snap_raster\n",
    "arcpy.env.overwriteOutput=True\n",
    "arcpy.env.scratchWorkspace=floodconfig.tempDir\n",
    "arcpy.env.workspace=floodconfig.workDir\n",
    "arcpy.env.rasterStatistics=\"STATISTICS\"\n",
    "arcpy.env.extent=\"MAXOF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a list of species occuring in the study region\n",
    "Code to whittle down the list of species to apply the slow geoprocessing to.\n",
    "The only species that need to be assessed are ones that are in the general study\n",
    "region and are associated with one of the ecological systems of interest in the \n",
    "database OR are handmodeled.  This code seeks to build that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a9d8ac7acd79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m###################################################  List species in general study region\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#########################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m studyRegionList = gp.gaprange.SppInAOI(AOIShp = AOI,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                        \u001b[0mhucShp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhucs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                        \u001b[0mworkDir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkDir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gp' is not defined"
     ]
    }
   ],
   "source": [
    "###################################################  List species in general study region\n",
    "#########################################################################################\n",
    "studyRegionList = gp.gaprange.SppInAOI(AOIShp = AOI,\n",
    "                                       hucShp = hucs, \n",
    "                                       workDir = workDir,\n",
    "                                       origin = [1], \n",
    "                                       season = [1, 3, 4],\n",
    "                                       reproduction = [1, 2, 3],\n",
    "                                       presence = [1, 2, 3])\n",
    "\n",
    "################################################  List species that don't use floodplains\n",
    "#########################################################################################\n",
    "# Get list of systems to use from Ecological systems of interest.csv\n",
    "df = pd.read_csv(floodplainSystemCSV)\n",
    "df1 = df[df[\"include\"] == 1]\n",
    "floodsystems = set(list(df1.map_code))\n",
    "\n",
    "# Find species that use a floodplain map unit.\n",
    "floodSp = []\n",
    "for sp in studyRegionList:\n",
    "    prim, aux = gp.gapmodeling.SpEcoSystems(spCode=sp, season='all', contiguousOnly=True)\n",
    "    primaux = set(gp.gapdb.MUNamesToCodes(prim)) | set(gp.gapdb.MUCodesToNames(aux))\n",
    "    if len(primaux & floodsystems) > 0:\n",
    "        floodSp.append(sp)\n",
    "    else:\n",
    "        print(sp + \" doesn't use floodplains\")\n",
    "floodSp = set(floodSp)\n",
    "\n",
    "#################################################################  List handmodel species\n",
    "#########################################################################################       \n",
    "handmodels = set([s[:6] for s in gp.gapmodeling.HandModels()])\n",
    "\n",
    "############################################################  Combine lists/sets and save\n",
    "#########################################################################################\n",
    "studyRegionList = set(studyRegionList)\n",
    "slimList = (handmodels & studyRegionList) | (floodSp & studyRegionList)\n",
    "\n",
    "# Save\n",
    "pickle.dump(list(slimList), open(resultDir + \"studyRegionList.pkl\", \"w\"))\n",
    "df = pd.DataFrame(list(slimList))\n",
    "df.rename(columns={0:\"strUC\"}, inplace=True)\n",
    "df[\"common_name\"] = [gp.gapdb.NameCommon(x) for x in df.strUC]\n",
    "df[\"scientific_name\"] = [gp.gapdb.NameSci(x) for x in df.strUC]\n",
    "df[\"subspecies_name\"] = [gp.gapdb.NameSubspecies(x) for x in df.strUC]\n",
    "df.to_csv(resultDir + \"Study Region Species List.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop a list of GAP ecological systems of interest\n",
    "Code to begin the development of a list of ecological systems\n",
    "of interest.  Note that a final step has to be performed by a human."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use wildclass sets to whittle down the list.\n",
    "broadTree = gp.wildclass.hasBroadTree()\n",
    "hasForest = gp.wildclass.hasForest()\n",
    "flooded = gp.wildclass.hasSaturatedSoil()\n",
    "satBroad = broadTree & flooded & hasForest\n",
    "\n",
    "# Save a table version of whittled down list for manual review.\n",
    "df = pd.DataFrame(list(satBroad))\n",
    "df.rename(columns={0:\"map_code\"}, inplace=True)\n",
    "df[\"system_name\"] = [gp.gapdb.MUName(m) for m in df.map_code]\n",
    "df.to_csv(intermDir + \"saturated and broad tree systems.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to open the \"saturated and broad treee systems.csv\" and \n",
    "put a \"1\" in an \"include\" column, then save as \"Ecological systems of interest.csv\"\n",
    "in the data directory.  That step has to be done by a human."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask species richness maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################  Mask the richness with the study region\n",
    "######################################################################################\n",
    "for group in richnessPathsCONUS:\n",
    "    print group\n",
    "    SE = arcpy.sa.ExtractByMask(arcpy.Raster(richnessPathsCONUS[group]), AOI)\n",
    "    SE.save(richnessPathsSE[group])\n",
    "    \n",
    "    \n",
    "#############################################  Mask the richness with the study region\n",
    "######################################################################################\n",
    "for group in richnessPathsCONUS:\n",
    "    print group\n",
    "    MU = arcpy.sa.ExtractByMask(arcpy.Raster(richnessPathsCONUS[group]), arcpy.Raster(floodplain))\n",
    "    MU.save(richnessPathsFlood[group])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map woody wetlands of the southeastern U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################## Map floodplain forests\n",
    "#########################################################################################\n",
    "# Get list of systems to use from Ecological systems of interest.csv\n",
    "df = pd.read_csv(floodplainSystemCSV)\n",
    "df1 = df[df[\"include\"] == 1]\n",
    "floodsystems = list(df1.map_code)\n",
    "\n",
    "# Reclass land cover to get a map of floodplain forests.\n",
    "print(\"Reclassifing lcv1\")\n",
    "ffMap1 = ga.landcover.ReclassLandCover(MUlist=floodsystems, \n",
    "                                       reclassTo=10, keyword=\"Floodplain\",\n",
    "                                       workDir=resultDir,\n",
    "                                       lcPath=lcMap,\n",
    "                                       lcVersion=\"1.1\")\n",
    "# Replace nulls with placeholder code\n",
    "print(\"Replacing null values\")\n",
    "arcpy.env.extent = conus_extent\n",
    "ffMap2 = arcpy.sa.Con(arcpy.sa.IsNull(ffMap1), placeholder_code, ffMap1)\n",
    "\n",
    "# Make sure valid RAT\n",
    "print(\"Checking or building statistics and RAT\")\n",
    "arcpy.management.CalculateStatistics(ffMap2, skip_existing=True)\n",
    "\n",
    "# Save\n",
    "print(\"Saving\")\n",
    "ffMap2.save(floodplainBinary)\n",
    "arcpy.management.BuildRasterAttributeTable(floodplainBinary, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much of each species' habitat is woody wetlands?\n",
    "These processes are slow (1 hr per species), so I broke them up into four lists\n",
    "to run simultaneously on different kernels.  The code here is what it would look like to run all on one kernel, which could take over a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################### Calculate representation on floodplains forests\n",
    "#########################################################################################\n",
    "# Calculate representation - kernel 1\n",
    "scratchDir = tempDir\n",
    "maps = null123List\n",
    "dfSpFF1 = ga.habitat.PercentOverlay(zoneFile=floodplainBinary,\n",
    "                                   zoneName=\"Floodplain\",\n",
    "                                   zoneField=\"VALUE\",\n",
    "                                   habmapList=maps,\n",
    "                                   habDir=habMapDir,\n",
    "                                   workDir=resultDir+\"Percent_FloodplainForest\",\n",
    "                                   snap=snap_raster,\n",
    "                                   scratchDir=scratchDir,\n",
    "                                   extent=\"zoneFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare richness in woody wetlands to CONUS and SE\n",
    "A figure with boxplots of richness from CONUS, SE, and floodplains would be\n",
    "ideal; but it's not easy to do that with RAT/frequency tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fontSize=9\n",
    "\n",
    "for group in richnessPathsCONUS.keys():\n",
    "    mainFig = plt.figure(figsize=(4,4), frameon=True)\n",
    "    mainFig.suptitle(group.title() + \" Species Richness\")\n",
    "    \n",
    "    conusStats = ga.misc.RATStats(richnessPathsCONUS[group],\n",
    "                                  percentile_list=[25, 50, 75],\n",
    "                                  dropMax=True, dropZero=True)\n",
    "    conusStats[\"name\"] = \"CONUS\"\n",
    "    seStats = ga.misc.RATStats(richnessPathsSE[group],\n",
    "                                  percentile_list=[25, 50, 75],\n",
    "                                  dropMax=True, dropZero=True)\n",
    "    seStats[\"name\"] = \"Southeast\"\n",
    "    floodStats = ga.misc.RATStats(richnessPathsFlood[group],\n",
    "                                  percentile_list=[25, 50, 75],\n",
    "                                  dropZero=True)\n",
    "    floodStats[\"name\"] = \"floodplains\"\n",
    "    \n",
    "    # CONUS\n",
    "    conusRAT = ga.misc.RATtoDataFrame(richnessPathsCONUS[group])\n",
    "    conusRAT = conusRAT[:-1]\n",
    "    conusRAT = conusRAT[conusRAT.index > 0]\n",
    "    ax1 = mainFig.add_subplot(2,2,2)\n",
    "    conusRAT.plot(ax=ax1, kind=\"line\", legend=False, title=\"\", color=\"blue\")\n",
    "    ax1.set_ylabel(\"Frequency (# grid cells)\")\n",
    "    \n",
    "    # SE\n",
    "    seRAT = ga.misc.RATtoDataFrame(richnessPathsSE[group])\n",
    "    seRAT = seRAT[seRAT.index > 0]\n",
    "    ax3 = mainFig.add_subplot(2,2,3)\n",
    "    seRAT.plot(ax=ax3, kind=\"line\", legend=False, title=\"\", color=\"orange\")\n",
    "    ax3.set_ylabel(\"Frequency (# grid cells)\")\n",
    "    \n",
    "    # Floodplains\n",
    "    floodRAT = ga.misc.RATtoDataFrame(richnessPathsFlood[group])\n",
    "    floodRAT = floodRAT[floodRAT.index > 0]\n",
    "    ax2 = mainFig.add_subplot(2,2,4)\n",
    "    floodRAT.plot(ax=ax2, kind=\"line\", legend=False, title=\"\", color=\"green\")\n",
    "    ax2.set_ylabel(\"Frequency (# grid cells)\")\n",
    "    \n",
    "    # Figure with comparison of means\n",
    "    meansDF = pd.DataFrame(index=[\"mean\"], columns=[\"CONUS\", \"Southeast\", \n",
    "                                                    \"floodplains\"])\n",
    "    meansDF.loc[\"mean\", \"CONUS\"] = conusStats[\"mean\"]\n",
    "    meansDF.loc[\"mean\", \"Southeast\"] = seStats[\"mean\"]\n",
    "    meansDF.loc[\"mean\", \"floodplains\"] = floodStats[\"mean\"]\n",
    "    ax4 = mainFig.add_subplot(2,2,1)\n",
    "    meansDF.plot(ax=ax4, kind=\"bar\", figsize=(5,5))\n",
    "    ax4.set_ylabel(\"Value\")\n",
    "    ax4.set_xlabel(\"Mean\")\n",
    "    ax4.axes.get_xaxis().set_ticks([])\n",
    "    if group == \"amphibian\":\n",
    "        plt.legend(loc=2)\n",
    "    else:\n",
    "        plt.legend(loc=3)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.02, bottom=.04, right=.99, top=.89, \n",
    "                        wspace=.5, hspace=.3)\n",
    "    \n",
    "    mainFig.savefig(resultDir + \"{0} mean chart.png\".format(group),\n",
    "                    bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize amounts of species' habitat in woody wetlands\n",
    "This code summarizes the results of the CalculatePercentHabitatInFloodplainForest.py\n",
    "and generates a descriptive table, lists of summer and winter species with dependence\n",
    "on the system, and graphs of frequency distribution of amount that species'\n",
    "habitat occurs in floodplain forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################## Read in master table\n",
    "###############################################################################\n",
    "df0 = pd.read_csv(overlayTable)\n",
    "\n",
    "###################################################### Add species name columns\n",
    "###############################################################################\n",
    "df0[\"common_name\"] = [gp.gapdb.NameCommon(s) for s in df0.strUC]\n",
    "df0[\"scientific_name\"] = [gp.gapdb.NameSci(s) for s in df0.strUC]\n",
    "\n",
    "############################################################# Descriptive stats\n",
    "###############################################################################\n",
    "# Remove placeholder rows and species with no ovelap in any season\n",
    "df1 = df0[df0.Zone != placeholder_code]\n",
    "df1 = df1[(df1.PercSummer != 0) | (df1.PercWinter != 0)]\n",
    "df2 = df1.drop([\"Zone\", \"NonHabitatPixels\", \"SummerPixels\", \"WinterPixels\", \n",
    "             \"AllYearPixels\", \"ZoneTotal\", \"SummerPixelTotal\", \"WinterPixelTotal\",\n",
    "             \"AllYearPixelTotal\", \"Date\", \"RunTime\", \"GeoTiff\", \"strUC\", \n",
    "             \"PercYearRound\"], axis=1)\n",
    "print(\"{0} species use the systems of interest\".format(len(df2)))\n",
    "df2.to_csv(resultDir + \"Species that use floodplain systems.csv\")\n",
    "\n",
    "# Summer and winter need to be described separately so that zeros can be\n",
    "# properly ommitted.\n",
    "descSum0 = df2.drop([\"PercWinter\", \"common_name\", \"scientific_name\"],\n",
    "                   axis=1)\n",
    "descSum = descSum0[descSum0.PercSummer > 0].describe(percentiles=np.arange(0, 1, .01))\n",
    "descSum.to_csv(resultDir + \"Overlay descriptive statistics SUMMER.csv\")\n",
    "descWint0 = df2.drop([\"PercSummer\", \"common_name\", \"scientific_name\"],\n",
    "                   axis=1)\n",
    "descWint = descWint0[descWint0.PercWinter > 0].describe(percentiles=np.arange(0, 1, .01))\n",
    "descWint.to_csv(resultDir + \"Overlay descriptive statistics WINTER.csv\")\n",
    "\n",
    "\n",
    "################################################ Box plots of summer and winter\n",
    "###############################################################################\n",
    "# Manipulate tables\n",
    "df1summer = df1.filter([\"strUC\", \"PercSummer\"], axis=1).set_index([\"strUC\"])\n",
    "df1winter = df1.filter([\"strUC\", \"PercWinter\"], axis=1).set_index([\"strUC\"])\n",
    "df1summer.rename(columns={\"PercSummer\":\"Summer\"}, inplace=True)\n",
    "df1winter.rename(columns={\"PercWinter\":\"Winter\"}, inplace=True)\n",
    "df1summer = df1summer[df1summer.Summer > 0]\n",
    "df1winter = df1winter[df1winter.Winter > 0]\n",
    "\n",
    "# Graph\n",
    "fig = plt.figure()\n",
    "ax2 = fig.add_subplot(1,2,1)\n",
    "df1summer.plot(ax = ax2, kind=\"box\", yticks=range(0,100, 10))\n",
    "ax2.set_ylabel(\"%\")\n",
    "ax3 = fig.add_subplot(1,2,2)\n",
    "df1winter.plot(ax = ax3, kind=\"box\", yticks=range(0,100, 10))\n",
    "fig.savefig(resultDir + \"Overlay boxplot.png\", dpi=600)\n",
    "\n",
    "\n",
    "############################################## Filter out non dependent species\n",
    "###############################################################################\n",
    "# Assign cutoff for filtering    ############################              What value to use?\n",
    "threshold = 50.0\n",
    "\n",
    "# Filter out the records corresponding to 0/nodata/99.\n",
    "dfSpFF = df0.loc[df0.Zone != placeholder_code]\n",
    "\n",
    "# Filter dataframe for top species and save, also make list for below\n",
    "winterSp = dfSpFF[dfSpFF[\"PercWinter\"] >= threshold]\n",
    "winterSp.to_csv(winterTopSpList)\n",
    "print(\"\\n{0} species with more than {1}% of winter habitat in floodplain forests:\".format(len(winterSp.strUC), threshold))\n",
    "for x in [gp.gapdb.NameCommon(x) for x in list(winterSp.strUC)]:\n",
    "    print(\"\\t\" + x)\n",
    "\n",
    "summerSp = dfSpFF[dfSpFF[\"PercSummer\"] >= threshold]\n",
    "summerSp.to_csv(summerTopSpList)\n",
    "print(\"\\n{0} species with more than {1}% of summer habitat in floodplain forests:\".format(len(summerSp.strUC), threshold))\n",
    "for x in [gp.gapdb.NameCommon(x) for x in list(summerSp.strUC)]:\n",
    "    print(\"\\t\" + x)\n",
    "\n",
    "topSp = dfSpFF[(dfSpFF[\"PercSummer\"] >= threshold) | (dfSpFF[\"PercWinter\"] >= threshold)]\n",
    "topSp.to_csv(TopSpList)\n",
    "\n",
    "\n",
    "######################################## Histogram of percSummer and percWinter\n",
    "###############################################################################\n",
    "# Summer\n",
    "df1summer = df1.filter([\"strUC\", \"PercSummer\"], axis=1).set_index([\"strUC\"])\n",
    "df1summer = df1summer[df1summer.PercSummer > 0]\n",
    "bins = np.arange(0, 110, 10)-5    # this enables bins to sit above x ticks, note it's 1 + desired bin number\n",
    "ax = df1summer.plot(kind=\"hist\", legend=False, color=['y'], bins=bins, # note limit is 1 + desired bin number\n",
    "                     xlim=(0,110))\n",
    "ax.set_xlabel(\"Percent of Species' Total Habitat Area\")\n",
    "ax.set_ylabel(\"Frequency (# species)\")\n",
    "fig = plt.gcf()\n",
    "fig.savefig(resultDir + \"Summer overlay histogram.png\", dpi=600)\n",
    "\n",
    "# Winter\n",
    "df1winter = df1.filter([\"strUC\", \"PercWinter\"], axis=1).set_index([\"strUC\"])\n",
    "df1winter = df1winter[df1winter.PercWinter > 0]\n",
    "ax3 = df1winter.plot(kind=\"hist\", legend=False, bins=bins, # note limit is 1 + desired bin number\n",
    "                     xlim=(0,110))\n",
    "ax3.set_xlabel(\"Percent of Species' Total Habitat Area\")\n",
    "ax3.set_ylabel(\"Frequency (# species)\")\n",
    "fig3 = plt.gcf()\n",
    "fig3.savefig(resultDir + \"Winter overlay histogram.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map the species richness of \"top\" woody wetland species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################### Map richness of top species (winter and summer)\n",
    "#####################################################################################\n",
    "# Winter\n",
    "winterDF = pd.read_csv(winterTopSpList)\n",
    "\n",
    "winterSp = list(winterDF.strUC)\n",
    "winterTiffs = [x + \"_v1.tif\" for x in winterSp]\n",
    "wRichnessMap = ga.richness.MapRichness(spp=winterTiffs, groupName=\"Top_Winter\",\n",
    "                                       outLoc=resultDir,\n",
    "                                       modelDir=seasonalhabMapDir,\n",
    "                                       season=\"Winter\",\n",
    "                                       intervalSize=40,\n",
    "                                       CONUSExtent=conus_extent)\n",
    "# Summer\n",
    "summerDF = pd.read_csv(summerTopSpList)\n",
    "summerSp = list(summerDF.strUC)\n",
    "summerTiffs = [x + \"_v1.tif\" for x in summerSp]\n",
    "sRichnessMap = ga.richness.MapRichness(spp=summerTiffs, groupName=\"Top_Summer\",\n",
    "                                       outLoc=resultDir, \n",
    "                                       modelDir=seasonalhabMapDir,\n",
    "                                       season=\"Summer\", \n",
    "                                       intervalSize=40,\n",
    "                                       CONUSExtent=conus_extent)\n",
    "\n",
    "\n",
    "#########################################  Mask the richness with the floodplain layer\n",
    "######################################################################################\n",
    "maskedWinter = arcpy.sa.ExtractByMask(wRichnessMap, arcpy.Raster(floodplainBinary))\n",
    "maskedWinter.save(resultDir + \"maskedRichnessWinter.tif\")\n",
    "\n",
    "maskedSummer = arcpy.sa.ExtractByMask(sRichnessMap, arcpy.Raster(floodplainBinary))\n",
    "maskedSummer.save(resultDir + \"maskedRichnessSummer.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess protection\n",
    "Produces results related to the protection of ecological systems\n",
    "and species.  Note that some processes (lines 33-35) take up to an hour to run\n",
    "and could be skipped if the floodPAD layer already exists. Also note that this\n",
    "code queries the Analytic Databse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################  How much of floodplain forest is protected?\n",
    "###############################################################################\n",
    "PAD = arcpy.Raster(PADUS_Man)\n",
    "FloodBin = arcpy.Raster(resultDir + \"Floodplain.tif\")\n",
    "\n",
    "# Overlay the PAD layer and binary floodplain layer\n",
    "floodPAD = PAD * (FloodBin - 9)\n",
    "floodPAD.save(resultDir + \"FloodplainPAD.tif\")\n",
    "\n",
    "# Make a pie chart of protection\n",
    "floodPADRAT = ga.misc.RATtoDataFrame(resultDir + \"FloodplainPAD.tif\")\n",
    "ax = floodPADRAT.plot(y=\"cell_count\", kind='Pie', figsize=(4,4), autopct='%.2f',\n",
    "                 legend=False,\n",
    "                 colors = [\"#009933\", \"#cccc00\", \"#999999\", \"#e6e6e6\"])\n",
    "ax.set_ylabel(\"%\")\n",
    "fig = plt.gcf()\n",
    "fig.savefig(resultDir + \"Flooplain protection.png\", dpi=600,\n",
    "            bbox_inches=\"tight\")\n",
    "\n",
    "############################## How much of each floodplain system is protected?\n",
    "###############################################################################\n",
    "def getEcoSysProtection(ecoSys):\n",
    "    '''\n",
    "    (string, list) -> pandas DataFrame\n",
    "    \n",
    "    Description:\n",
    "    A function that returns the percentage of an ecological system\n",
    "        that is in the GAP PAD statuses of interest.\n",
    "    \n",
    "    Argument:\n",
    "    ecoSys -- The name of the ecological system that you are interested in.\n",
    "    '''\n",
    "    blank = pd.DataFrame(index = [\"1\",\"2\",\"3\",\"4\", \"1234\"], \n",
    "                         columns=[\"cells\", \"percent\"])\n",
    "    try:\n",
    "        # Connect to analytic database\n",
    "        anCur, anCon = gp.gapdb.ConnectAnalyticDB()\n",
    "        \n",
    "        sql = \"\"\"\n",
    "        --Retrieve ecological system boundary info for one system.\n",
    "        WITH ESPAD AS (\n",
    "        SELECT lu_boundary_gap_landfire.boundary, lu_boundary_gap_landfire.count,\n",
    "               lu_boundary_gap_landfire.gap_landfire, lu_boundary.value, lu_boundary.padus1_4, \n",
    "               padus1_4.revoid, padus1_4.gap_sts\n",
    "        FROM lu_boundary_gap_landfire \n",
    "        INNER JOIN lu_boundary ON lu_boundary.value = lu_boundary_gap_landfire.boundary\n",
    "        INNER JOIN padus1_4 ON lu_boundary.padus1_4 = padus1_4.revoid),\n",
    "        \n",
    "        --Retrieve ecological system name and code\n",
    "        ECOSYS AS (\n",
    "        SELECT g.ecosys_lu, g.value\n",
    "        FROM gap_landfire as g\n",
    "        WHERE g.ecosys_lu = '{0}')\n",
    "        \n",
    "        --Group records from joined data views by count\n",
    "        SELECT ESPAD.gap_sts, sum(ESPAD.count) AS cells\n",
    "        FROM ECOSYS INNER JOIN ESPAD ON ECOSYS.value = ESPAD.gap_landfire\n",
    "        GROUP BY ESPAD.gap_sts\n",
    "        \"\"\".format(ecoSys)\n",
    "        \n",
    "        qryDF = pd.read_sql(sql, anCon).set_index(\"gap_sts\")\n",
    "        qryDF.loc[\"1234\", \"cells\"] = sum(qryDF.cells)\n",
    "        qryDF[\"percent\"] = [100*(qryDF.loc[i, \"cells\"]/qryDF.loc[\"1234\", \"cells\"]) for i in qryDF.index]\n",
    "        \n",
    "        del anCur\n",
    "        anCon.close()\n",
    "        \n",
    "        for x in qryDF.index:\n",
    "            blank.loc[x, \"cells\"] = qryDF.loc[x, \"cells\"]\n",
    "            blank.loc[x, \"percent\"] = qryDF.loc[x, \"percent\"]\n",
    "            blank.fillna(0, inplace=True)\n",
    "        return blank\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "floodSysDF = pd.read_csv(floodplainSystemCSV)\n",
    "floodSysDF = floodSysDF[floodSysDF.include == 1]\n",
    "floodSysDF.drop([\"notes\", \"include\"], inplace=True, axis=1)\n",
    "floodSysDF[\"protected1&2(%)\"] = [sum(getEcoSysProtection(i).iloc[:2].percent) for i in floodSysDF.system_name]\n",
    "floodSysDF.to_csv(resultDir + \"EcolSysProtection.csv\")\n",
    "\n",
    "###############################################  Protection of species' habitat\n",
    "###############################################################################\n",
    "# Function to return protection status of a species.\n",
    "def getProtection(strUC, season):\n",
    "    '''\n",
    "    (string, string) -> pandas DataFrame\n",
    "    \n",
    "    Description:\n",
    "    A function that returns the amount of a species' habitat that is in status\n",
    "    1, 2, 3, and 4 lands by season.\n",
    "    \n",
    "    Arguments:\n",
    "    strUC -- Species code (e.g., \"mVASHx\")\n",
    "    season -- Season to summarize on (i.e., summer, winter, or all year)\n",
    "    '''\n",
    "    try:\n",
    "        seasonDict = {\"summer\":(1,3), \"winter\":(2,3), \"all year\":(3,3)}\n",
    "        \n",
    "        # Connect to analytic database\n",
    "        anCur, anCon = gp.gapdb.ConnectAnalyticDB()\n",
    "        \n",
    "        sql = \"\"\"\n",
    "        --Retrieve species boundary info for one species.\n",
    "        WITH SpPAD AS (\n",
    "        SELECT lu_boundary_species.boundary, lu_boundary_species.count, \n",
    "               lu_boundary_species.season, lu_boundary_species.species_cd, \n",
    "               lu_boundary.value, lu_boundary.padus1_4, padus1_4.revoid, \n",
    "               padus1_4.gap_sts\n",
    "        FROM lu_boundary_species \n",
    "        INNER JOIN lu_boundary ON lu_boundary.value = lu_boundary_species.boundary\n",
    "        INNER JOIN padus1_4 ON lu_boundary.padus1_4 = padus1_4.revoid\n",
    "        WHERE (lu_boundary_species.species_cd = '{0}' \n",
    "               and (lu_boundary_species.season = {1} or lu_boundary_species.season = {2})))\n",
    "        \n",
    "        \n",
    "        --Group by count\n",
    "        SELECT  s.gap_sts, sum(s.count) AS cells\n",
    "        FROM SpPAD AS s\n",
    "        GROUP BY s.gap_sts\n",
    "        \"\"\".format(strUC, str(seasonDict[season][0]), str(seasonDict[season][1]))\n",
    "        \n",
    "        qryDF = pd.read_sql(sql, anCon).set_index(\"gap_sts\")\n",
    "        \n",
    "        del anCur\n",
    "        anCon.close()\n",
    "        \n",
    "        return qryDF\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Get list of species to query.\n",
    "summerDF = pd.read_csv(summerTopSpList)\n",
    "summerSp = list(summerDF.strUC)\n",
    "winterDF = pd.read_csv(winterTopSpList)\n",
    "winterSp = list(winterDF.strUC)\n",
    "\n",
    "# Empty dataframes to fill out.\n",
    "summer0 = pd.DataFrame(index=summerSp, \n",
    "                       columns=[\"status_1\", \"status_2\", \"status_3\", \"status_4\"])\n",
    "winter0 = pd.DataFrame(index=winterSp, \n",
    "                       columns=[\"status_1\", \"status_2\", \"status_3\", \"status_4\"])\n",
    "\n",
    "#### Fill out summer DF\n",
    "print(\"\\n*** SUMMER ***\")\n",
    "for sp in summerSp:\n",
    "    prot = getProtection(sp, season=\"summer\")\n",
    "    try:\n",
    "        summer0.loc[sp, 'status_1'] = int(prot.loc[\"1\"])\n",
    "    except: \n",
    "        summer0.loc[sp, 'status_1'] = 0\n",
    "    try:\n",
    "        summer0.loc[sp, 'status_2'] = int(prot.loc[\"2\"])\n",
    "    except:\n",
    "        summer0.loc[sp, 'status_2'] = 0\n",
    "    try:\n",
    "        summer0.loc[sp, 'status_3'] = int(prot.loc[\"3\"])\n",
    "    except:\n",
    "        summer0.loc[sp, 'status_3'] = 0\n",
    "    try:\n",
    "        summer0.loc[sp, 'status_4'] = int(prot.loc[\"4\"])\n",
    "    except:\n",
    "        summer0.loc[sp, 'status_4'] = 0\n",
    "summer0[\"total_cells\"] = summer0.status_1 + summer0.status_2 + summer0.status_3 + summer0.status_4\n",
    "summer0['status_1%'] = 100.*summer0.status_1/summer0.total_cells\n",
    "summer0['status_2%'] = 100.*summer0.status_2/summer0.total_cells\n",
    "summer0['status_3%'] = 100.*summer0.status_3/summer0.total_cells\n",
    "summer0['status_4%'] = 100.*summer0.status_4/summer0.total_cells\n",
    "\n",
    "# Summer protection description\n",
    "summer1 = summer0.apply(pd.to_numeric)\n",
    "summer1.to_csv(resultDir + \"Summer protection.csv\")\n",
    "summerProtDesc = summer1.describe()\n",
    "print(summerProtDesc)\n",
    "summerProtDesc.to_csv(resultDir + \"Summer protection descriptive stats.csv\")\n",
    "    \n",
    "# Graph protection\n",
    "dropCols = [\"status_1\", \"status_2\", \"status_3\", \"status_4\", \"total_cells\"]\n",
    "# Summer\n",
    "summer2 = summer1.drop(dropCols, axis=1)\n",
    "summer2.rename(columns={\"status_1%\":\"1\", \"status_2%\":\"2\",\"status_3%\":\"3\",\n",
    "                        \"status_4%\":\"4\",}, inplace=True)\n",
    "sumAx = summer2.plot(kind=\"box\", title=\"Summer\", yticks=range(0,100,10),\n",
    "                     figsize=(5,4))\n",
    "sumAx.set_ylabel(\"Percent of Species' Total Habitat Area\")\n",
    "sumAx.set_xlabel(\"GAP Protection Status\")\n",
    "fig = plt.gcf()\n",
    "fig.savefig(resultDir + \"Protection Boxplot Summer.png\", dpi=600,\n",
    "            bbox_inches=\"tight\")\n",
    "\n",
    "#### Fill out winter DF\n",
    "print(\"\\n*** WINTER ***\")\n",
    "for sp in winterSp:\n",
    "    prot = getProtection(sp, season=\"winter\")\n",
    "    try:\n",
    "        winter0.loc[sp, 'status_1'] = int(prot.loc[\"1\"])\n",
    "    except: \n",
    "        winter0.loc[sp, 'status_1'] = 0\n",
    "    try:\n",
    "        winter0.loc[sp, 'status_2'] = int(prot.loc[\"2\"])\n",
    "    except:\n",
    "        winter0.loc[sp, 'status_2'] = 0\n",
    "    try:\n",
    "        winter0.loc[sp, 'status_3'] = int(prot.loc[\"3\"])\n",
    "    except:\n",
    "        winter0.loc[sp, 'status_3'] = 0\n",
    "    try:\n",
    "        winter0.loc[sp, 'status_4'] = int(prot.loc[\"4\"])\n",
    "    except:\n",
    "        winter0.loc[sp, 'status_4'] = 0\n",
    "        \n",
    "winter0[\"total_cells\"] = winter0.status_1 + winter0.status_2 + winter0.status_3 + winter0.status_4\n",
    "winter0['status_1%'] = 100.*winter0.status_1/winter0.total_cells\n",
    "winter0['status_2%'] = 100.*winter0.status_2/winter0.total_cells\n",
    "winter0['status_3%'] = 100.*winter0.status_3/winter0.total_cells\n",
    "winter0['status_4%'] = 100.*winter0.status_4/winter0.total_cells\n",
    "\n",
    "# Winter protection description\n",
    "winter1 = winter0.apply(pd.to_numeric)\n",
    "winter1.to_csv(resultDir + \"Winter protection.csv\")\n",
    "winterProtDesc = winter1.describe()\n",
    "print(winterProtDesc)\n",
    "winterProtDesc.to_csv(resultDir + \"Winter protection descriptive stats.csv\")\n",
    "\n",
    "# Winter\n",
    "winter2 = winter1.drop(dropCols, axis=1)\n",
    "winter2.rename(columns={\"status_1%\":\"1\", \"status_2%\":\"2\",\"status_3%\":\"3\",\n",
    "                        \"status_4%\":\"4\",}, inplace=True)\n",
    "wintAx = winter2.plot(kind=\"box\", title=\"Winter\", yticks=range(0,100,10),\n",
    "                      figsize=(5,4))\n",
    "wintAx.set_ylabel(\"Percent of Species' Total Habitat Area\")\n",
    "wintAx.set_xlabel(\"GAP Protection Status\")\n",
    "fig = plt.gcf()\n",
    "fig.savefig(resultDir + \"Protection Boxplot Winter.png\", dpi=600,\n",
    "            bbox_inches=\"tight\")\n",
    "\n",
    "#######################  Make table of status 1 or 2 protection for top species\n",
    "###############################################################################\n",
    "# get combined species list\n",
    "tops = set(summerSp) | set(winterSp)\n",
    "\n",
    "# Define function to find out how much habitat is in status 1 or 2\n",
    "def status1or2(strUC, season):\n",
    "    '''\n",
    "    (string, string) -> float\n",
    "    \n",
    "    Description:\n",
    "        Determines what percentage of species's seasonal habitat is in status\n",
    "    1 or 2.\n",
    "    '''\n",
    "    # Blank DataFrame to fill out\n",
    "    blank = pd.DataFrame(index = [\"1\",\"2\",\"3\",\"4\"], \n",
    "                         columns=[\"cells\", \"percent\"])\n",
    "    # Get the protection amounts from Analytic DB\n",
    "    one = getProtection(strUC, season)\n",
    "    # Fill out the blank table, use this blank so that errors don't occur\n",
    "    # if a species' habitat is all in less than 4 statuses.\n",
    "    for x in one.index:\n",
    "            blank.loc[x, \"cells\"] = one.loc[x, \"cells\"]\n",
    "            blank.fillna(0, inplace=True)\n",
    "    # get total count and calculate the percentage in 1 or 2 status.\n",
    "    total = float(blank.cells.sum())\n",
    "    protDF = blank.iloc[:2]\n",
    "    protCells = protDF.cells.sum()\n",
    "    return 100*(protCells/total)\n",
    "  \n",
    "# Fill out a DataFrame\n",
    "df10 = pd.DataFrame(index=tops, columns=[\"summer\", \"winter\"])\n",
    "df10[\"common_name\"] = [gp.gapdb.NameCommon(s) for s in df10.index]\n",
    "df10[\"summer\"] = [status1or2(strUC, \"summer\") for strUC in df10.index]\n",
    "df10[\"winter\"] = [status1or2(strUC, \"winter\") for strUC in df10.index]\n",
    "df10.fillna(0, inplace=True).sort()\n",
    "df10.to_csv(resultDir + \"TopSpeciesProtection1or2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
